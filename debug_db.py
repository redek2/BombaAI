import chromadb
from transformers import AutoTokenizer
import sys

# --- Konfiguracja (musi byÄ‡ taka sama jak w skryptach) ---
DB_PATH = "./chroma_db"
TOKENIZER_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

def analyze_database():
    print("--- ğŸ•µï¸â€â™‚ï¸ Rozpoczynam AnalizÄ™ Bazy Danych ChromaDB ---")

    try:
        # UÅ¼ywamy tej samej "linijki" (tokenizera) co model RAG
        print(f"ÅadujÄ™ tokenizer: {TOKENIZER_NAME}...")
        tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME)
        print("Tokenizer zaÅ‚adowany.")

        # ÅÄ…czymy siÄ™ z *istniejÄ…cÄ…* bazÄ… danych
        print(f"ÅadujÄ™ bazÄ™ danych z: {DB_PATH}...")
        db = chromadb.PersistentClient(path=DB_PATH)
        collection = db.get_collection("bomba_lore")
        print("Baza danych zaÅ‚adowana.")

        # Pobieramy WSZYSTKIE dokumenty z bazy
        print("Pobieram *wszystkie* fragmenty z bazy (to moÅ¼e chwilÄ™ potrwaÄ‡)...")
        results = collection.get(include=["documents"])
        documents = results['documents']
        total_chunks = len(documents)

        if total_chunks == 0:
            print("BÅÄ„D: Baza danych jest pusta!")
            return

        print(f"Pobrano {total_chunks} fragmentÃ³w. AnalizujÄ™ dÅ‚ugoÅ›Ä‡ kaÅ¼dego z nich...")

        # Mierzymy dÅ‚ugoÅ›Ä‡ kaÅ¼dego fragmentu
        lengths = []
        for doc in documents:
            # UÅ¼ywamy .encode(), a nie .tokenize(), aby dostaÄ‡ listÄ™ ID tokenÃ³w
            tokens = tokenizer.encode(doc, add_special_tokens=False)
            lengths.append(len(tokens))

        # Analiza statystyczna
        max_len = max(lengths)
        min_len = min(lengths)
        avg_len = sum(lengths) / total_chunks

        # Szukamy "potwornych fragmentÃ³w"
        over_512 = sum(1 for l in lengths if l > 512)
        over_1024 = sum(1 for l in lengths if l > 1024)
        over_2048 = sum(1 for l in lengths if l > 2048) # To sÄ… te, ktÃ³re psujÄ… nam czat

        print("\n" + "="*50)
        print("--- WYNIKI ANALIZY BAZY DANYCH (chroma_db) ---")
        print(f"IloÅ›Ä‡ wszystkich fragmentÃ³w (chunkÃ³w): {total_chunks}")
        print(f"Åšrednia dÅ‚ugoÅ›Ä‡ fragmentu: {avg_len:.2f} tokenÃ³w")
        print(f"Minimalna dÅ‚ugoÅ›Ä‡ fragmentu: {min_len} tokenÃ³w")
        print(f"!!! MAKSYMALNA dÅ‚ugoÅ›Ä‡ fragmentu: {max_len} tokenÃ³w !!!")
        print("-" * 50)
        print(f"Fragmenty dÅ‚uÅ¼sze niÅ¼ 512 tokenÃ³w: {over_512}")
        print(f"Fragmenty dÅ‚uÅ¼sze niÅ¼ 1024 tokeny: {over_1024}")
        print(f"Fragmenty dÅ‚uÅ¼sze niÅ¼ 2048 tokenÃ³w: {over_2048}")
        print("="*50)

    except Exception as e:
        print(f"WystÄ…piÅ‚ bÅ‚Ä…d podczas analizy: {e}", file=sys.stderr)

if __name__ == "__main__":
    analyze_database()